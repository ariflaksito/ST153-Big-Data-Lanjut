{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "u0dtbL3W9upc"
      },
      "outputs": [],
      "source": [
        "# creating Spark session\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.getOrCreate()\n",
        "spark = SparkSession.builder\\\n",
        "        .master(\"local\")\\\n",
        "        .appName(\"RDD\")\\\n",
        "        .config('spark.ui.port', '4050')\\\n",
        "        .getOrCreate()\n",
        "\n",
        "spark\n",
        "sc = spark.sparkContext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nILmBxOq8sWh"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "from pyspark.ml.feature import HashingTF, Tokenizer\n",
        "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
        "\n",
        "# Prepare training documents, which are labeled.\n",
        "training = spark.createDataFrame([\n",
        "    (0, \"a b c d e spark\", 1.0),\n",
        "    (1, \"b d\", 0.0),\n",
        "    (2, \"spark f g h\", 1.0),\n",
        "    (3, \"hadoop mapreduce\", 0.0),\n",
        "    (4, \"b spark who\", 1.0),\n",
        "    (5, \"g d a y\", 0.0),\n",
        "    (6, \"spark fly\", 1.0),\n",
        "    (7, \"was mapreduce\", 0.0),\n",
        "    (8, \"e spark program\", 1.0),\n",
        "    (9, \"a e c l\", 0.0),\n",
        "    (10, \"spark compile\", 1.0),\n",
        "    (11, \"hadoop software\", 0.0)\n",
        "], [\"id\", \"text\", \"label\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72IjDnHMCbDp",
        "outputId": "145bf2e2-6a95-47bf-b544-08e4a96e5113"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---+----------------+-----+\n",
            "| id|            text|label|\n",
            "+---+----------------+-----+\n",
            "|  0| a b c d e spark|  1.0|\n",
            "|  1|             b d|  0.0|\n",
            "|  2|     spark f g h|  1.0|\n",
            "|  3|hadoop mapreduce|  0.0|\n",
            "|  4|     b spark who|  1.0|\n",
            "|  5|         g d a y|  0.0|\n",
            "|  6|       spark fly|  1.0|\n",
            "|  7|   was mapreduce|  0.0|\n",
            "|  8| e spark program|  1.0|\n",
            "|  9|         a e c l|  0.0|\n",
            "| 10|   spark compile|  1.0|\n",
            "| 11| hadoop software|  0.0|\n",
            "+---+----------------+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "training.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "iFIBjWQ9CMGw"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Configure an ML pipeline, which consists of tree stages: tokenizer, hashingTF, and lr.\n",
        "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
        "hashingTF = HashingTF(inputCol=tokenizer.getOutputCol(), outputCol=\"features\")\n",
        "lr = LogisticRegression(maxIter=10)\n",
        "pipeline = Pipeline(stages=[tokenizer, hashingTF, lr])\n",
        "\n",
        "# We now treat the Pipeline as an Estimator, wrapping it in a CrossValidator instance.\n",
        "# This will allow us to jointly choose parameters for all Pipeline stages.\n",
        "# A CrossValidator requires an Estimator, a set of Estimator ParamMaps, and an Evaluator.\n",
        "# We use a ParamGridBuilder to construct a grid of parameters to search over.\n",
        "# With 3 values for hashingTF.numFeatures and 2 values for lr.regParam,\n",
        "# this grid will have 3 x 2 = 6 parameter settings for CrossValidator to choose from.\n",
        "paramGrid = ParamGridBuilder() \\\n",
        "    .addGrid(hashingTF.numFeatures, [10, 100, 1000]) \\\n",
        "    .addGrid(lr.regParam, [0.1, 0.01]) \\\n",
        "    .build()\n",
        "\n",
        "crossval = CrossValidator(estimator=pipeline,\n",
        "                          estimatorParamMaps=paramGrid,\n",
        "                          evaluator=BinaryClassificationEvaluator(),\n",
        "                          numFolds=2)  # use 3+ folds in practice\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NVAXeyR_CkfJ",
        "outputId": "3d2ea3ae-1a36-4809-f453-9eadf9db9952"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Row(id=0, text='a b c d e spark', label=1.0, words=['a', 'b', 'c', 'd', 'e', 'spark']),\n",
              " Row(id=1, text='b d', label=0.0, words=['b', 'd']),\n",
              " Row(id=2, text='spark f g h', label=1.0, words=['spark', 'f', 'g', 'h']),\n",
              " Row(id=3, text='hadoop mapreduce', label=0.0, words=['hadoop', 'mapreduce']),\n",
              " Row(id=4, text='b spark who', label=1.0, words=['b', 'spark', 'who']),\n",
              " Row(id=5, text='g d a y', label=0.0, words=['g', 'd', 'a', 'y']),\n",
              " Row(id=6, text='spark fly', label=1.0, words=['spark', 'fly']),\n",
              " Row(id=7, text='was mapreduce', label=0.0, words=['was', 'mapreduce']),\n",
              " Row(id=8, text='e spark program', label=1.0, words=['e', 'spark', 'program']),\n",
              " Row(id=9, text='a e c l', label=0.0, words=['a', 'e', 'c', 'l'])]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# melihat hasil tokenize\n",
        "tokenizer.transform(training).head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "nmsPFy9LDNU6"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
        "hashingTF = HashingTF(inputCol=tokenizer.getOutputCol(), outputCol=\"features\")\n",
        "\n",
        "# hashingTF.transform(tokenizer).head().features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IB1wu-XyFTBA",
        "outputId": "4a311f87-b58e-4974-adb1-93f5220911a9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "107107"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "hashingTF.indexOf(\"a\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "aYGZ0mEhCV6_"
      },
      "outputs": [],
      "source": [
        "# Run cross-validation, and choose the best set of parameters.\n",
        "cvModel = crossval.fit(training)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "NNVuz-TwMlG4",
        "outputId": "89664f2d-6cce-430c-82ce-942170892af5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"estimator: estimator to be cross-validated (current: Pipeline_cf2e9e9ba919)\\nestimatorParamMaps: estimator param maps (current: [{Param(parent='HashingTF_912b6e61bf61', name='numFeatures', doc='Number of features. Should be greater than 0.'): 10, Param(parent='LogisticRegression_d1750c91bac2', name='regParam', doc='regularization parameter (>= 0).'): 0.1}, {Param(parent='HashingTF_912b6e61bf61', name='numFeatures', doc='Number of features. Should be greater than 0.'): 10, Param(parent='LogisticRegression_d1750c91bac2', name='regParam', doc='regularization parameter (>= 0).'): 0.01}, {Param(parent='HashingTF_912b6e61bf61', name='numFeatures', doc='Number of features. Should be greater than 0.'): 100, Param(parent='LogisticRegression_d1750c91bac2', name='regParam', doc='regularization parameter (>= 0).'): 0.1}, {Param(parent='HashingTF_912b6e61bf61', name='numFeatures', doc='Number of features. Should be greater than 0.'): 100, Param(parent='LogisticRegression_d1750c91bac2', name='regParam', doc='regularization parameter (>= 0).'): 0.01}, {Param(parent='HashingTF_912b6e61bf61', name='numFeatures', doc='Number of features. Should be greater than 0.'): 1000, Param(parent='LogisticRegression_d1750c91bac2', name='regParam', doc='regularization parameter (>= 0).'): 0.1}, {Param(parent='HashingTF_912b6e61bf61', name='numFeatures', doc='Number of features. Should be greater than 0.'): 1000, Param(parent='LogisticRegression_d1750c91bac2', name='regParam', doc='regularization parameter (>= 0).'): 0.01}])\\nevaluator: evaluator used to select hyper-parameters that maximize the validator metric (current: BinaryClassificationEvaluator_c7098f42b76e)\\nfoldCol: Param for the column name of user specified fold number. Once this is specified, :py:class:`CrossValidator` won't do random k-fold split. Note that this column should be integer type with range [0, numFolds) and Spark will throw exception on out-of-range fold numbers. (default: )\\nnumFolds: number of folds for cross validation (default: 3, current: 2)\\nseed: random seed. (default: 1125949221178986208)\""
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cvModel.explainParams()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7tOyL7ZrNilr",
        "outputId": "c718acc8-14b6-484a-a533-767aa004c372"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PipelineModel_85e57532ddeb"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bestModel = cvModel.bestModel\n",
        "bestModel\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rf_euasBCWFA",
        "outputId": "54d93e30-7018-4512-ea86-49e4707dd195"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Row(id=4, text='spark i j k', probability=DenseVector([0.0251, 0.9749]), prediction=1.0)\n",
            "Row(id=5, text='l m n', probability=DenseVector([0.8148, 0.1852]), prediction=0.0)\n",
            "Row(id=6, text='mapreduce spark', probability=DenseVector([0.4425, 0.5575]), prediction=1.0)\n",
            "Row(id=7, text='apache hadoop', probability=DenseVector([0.764, 0.236]), prediction=0.0)\n"
          ]
        }
      ],
      "source": [
        "# Prepare test documents, which are unlabeled.\n",
        "test = spark.createDataFrame([\n",
        "    (4, \"spark i j k\"),\n",
        "    (5, \"l m n\"),\n",
        "    (6, \"mapreduce spark\"),\n",
        "    (7, \"apache hadoop\")\n",
        "], [\"id\", \"text\"])\n",
        "\n",
        "# Make predictions on test documents. cvModel uses the best model found (lrModel).\n",
        "prediction = cvModel.transform(test)\n",
        "selected = prediction.select(\"id\", \"text\", \"probability\", \"prediction\")\n",
        "for row in selected.collect():\n",
        "    print(row)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "5bc067213193d7d391907c464a8e66c6ece1a82666c1d2406921e2c8deb6cf3c"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
